{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92 64 95 ... 76 73 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90804598]\n",
      " [0.5862069 ]\n",
      " [0.94252874]\n",
      " ...\n",
      " [0.72413793]\n",
      " [0.68965517]\n",
      " [0.2183908 ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple tf.keras Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaialble:  0\n"
     ]
    }
   ],
   "source": [
    "physial_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Avaialble: \", len(physial_devices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'), # irst hidden layer - 16 neurons\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 - 0s - loss: 0.6704 - accuracy: 0.5386 - val_loss: 0.6551 - val_accuracy: 0.5762\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.6341 - accuracy: 0.6471 - val_loss: 0.6200 - val_accuracy: 0.6333\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.5934 - accuracy: 0.7058 - val_loss: 0.5799 - val_accuracy: 0.7238\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.5545 - accuracy: 0.7667 - val_loss: 0.5448 - val_accuracy: 0.7381\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.5134 - accuracy: 0.8196 - val_loss: 0.5025 - val_accuracy: 0.7810\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.4686 - accuracy: 0.8508 - val_loss: 0.4588 - val_accuracy: 0.8286\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.4203 - accuracy: 0.8878 - val_loss: 0.4120 - val_accuracy: 0.8619\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.3741 - accuracy: 0.9063 - val_loss: 0.3689 - val_accuracy: 0.8952\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.3329 - accuracy: 0.9259 - val_loss: 0.3322 - val_accuracy: 0.9048\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.2969 - accuracy: 0.9360 - val_loss: 0.2987 - val_accuracy: 0.9190\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.2651 - accuracy: 0.9460 - val_loss: 0.2707 - val_accuracy: 0.9190\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.2381 - accuracy: 0.9487 - val_loss: 0.2436 - val_accuracy: 0.9571\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.2149 - accuracy: 0.9582 - val_loss: 0.2227 - val_accuracy: 0.9571\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.1956 - accuracy: 0.9603 - val_loss: 0.2033 - val_accuracy: 0.9619\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.1794 - accuracy: 0.9698 - val_loss: 0.1897 - val_accuracy: 0.9571\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.1655 - accuracy: 0.9672 - val_loss: 0.1749 - val_accuracy: 0.9619\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.1534 - accuracy: 0.9698 - val_loss: 0.1632 - val_accuracy: 0.9619\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.1433 - accuracy: 0.9735 - val_loss: 0.1543 - val_accuracy: 0.9619\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.1343 - accuracy: 0.9720 - val_loss: 0.1449 - val_accuracy: 0.9619\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.1267 - accuracy: 0.9720 - val_loss: 0.1376 - val_accuracy: 0.9619\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.1198 - accuracy: 0.9804 - val_loss: 0.1308 - val_accuracy: 0.9619\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.1138 - accuracy: 0.9788 - val_loss: 0.1247 - val_accuracy: 0.9714\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.1084 - accuracy: 0.9757 - val_loss: 0.1202 - val_accuracy: 0.9619\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.1036 - accuracy: 0.9804 - val_loss: 0.1141 - val_accuracy: 0.9714\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.0989 - accuracy: 0.9778 - val_loss: 0.1080 - val_accuracy: 0.9714\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.0951 - accuracy: 0.9825 - val_loss: 0.1048 - val_accuracy: 0.9714\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.0915 - accuracy: 0.9841 - val_loss: 0.1017 - val_accuracy: 0.9714\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.0881 - accuracy: 0.9831 - val_loss: 0.0990 - val_accuracy: 0.9714\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.0851 - accuracy: 0.9820 - val_loss: 0.0949 - val_accuracy: 0.9714\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.0823 - accuracy: 0.9836 - val_loss: 0.0918 - val_accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1daa0eccaf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(scaled_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0135096  0.98649037]\n",
      " [0.5729432  0.42705682]\n",
      " [0.2973276  0.7026724 ]\n",
      " [0.11774272 0.8822573 ]\n",
      " [0.0036547  0.99634534]\n",
      " [0.09580184 0.90419817]\n",
      " [0.62823546 0.37176454]\n",
      " [0.9553528  0.04464718]\n",
      " [0.00454504 0.9954549 ]\n",
      " [0.7283415  0.2716585 ]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_prediction = np.argmax(prediction, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(rounded_prediction[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KAVINDA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\KAVINDA\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\KAVINDA\\AppData\\Local\\Temp\\tmp2lchde9u\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4248"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "tfmodel = converter.convert()\n",
    "open(\"linear.tflite\", \"wb\").write(tfmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BLE RSSI Values to Classify Proximity with Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
